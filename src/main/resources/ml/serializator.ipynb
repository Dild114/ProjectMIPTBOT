{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель успешно сериализована в model.onnx\n",
      "Токенайзер успешно сохранён\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Загрузка предобученной модели и токенизатора\n",
    "model_name = \"cross-encoder/nli-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Переводим модель в режим оценки, т.к. больше не будем её обучать, и нам необходимы только её предсказания.\n",
    "model.eval()\n",
    "\n",
    "text = \"Как настроить CI/CD для проекта на GitLab?\"\n",
    "candidate_labels = [\"DevOps\", \"IT\", \"Frontend\", \"Backend\", \"Data Science\", \"Machine Learning\", \"Cybersecurity\", \"Cloud Computing\", \"Mobile Development\", \"Game Development\", \"Database Administration\"]\n",
    "\n",
    "#Создаём пример входных данных.\n",
    "# Для данной модели токенизатор возвращает тензор, содержащий идентификаторы токенов для текста, и тензор, указывающий, какие токены следует учитывать во входных данных.\n",
    "inputs = tokenizer([text] * 11, candidate_labels, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "fileForSavingTheModel = 'model.onnx'\n",
    "torch.onnx.export(\n",
    "    model = model, # Какую модель сериализуем.\n",
    "    args = (inputs['input_ids'], inputs['attention_mask']), # Пример аргументов, принимаемых моделью, чтобы она +- понимала, какие тензоры ей ожидать.\n",
    "    f = fileForSavingTheModel, # Путь к сохранению сериализованной модели.\n",
    "    input_names = [\"input_ids\", \"attention_mask\"], # Модель принимает два тензора.\n",
    "    output_names = [\"logits\"], # Модель возвращает сырые логиты, по 3 на каждую категорию:\n",
    "    #[следуют друг из друга, противоречат друг другу, никак не связаны]\n",
    "    dynamic_axes={  # Указание динамических осей.\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},  # Т.к. 0 - может поступить сразу несколько категорий, и их данные могут отличаться, 1 - данные могут быть разной длины.\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},  # Аналогично с input_ids.\n",
    "        \"logits\": {0: \"batch_size\"}  # Т.к. может поступить несколько категорий, значит понадобится вывести несколько ответов.\n",
    "    },\n",
    ")\n",
    "print(\"Модель успешно сериализована в\", fileForSavingTheModel)\n",
    "tokenizer.save_pretrained(\"tokenizer\")\n",
    "print(\"Токенайзер успешно сохранён\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
